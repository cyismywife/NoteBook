爬虫笔记

1， 正则表达式

[\u4E00-\u9FA5] # 代表汉字的区间 
\d  # 表示匹配数字类的

实例：
import re

line1 = 'XXX出生于2001年6月1日'
line2 = 'XXX出生于2001/6/1'
line3 = 'XXX出生于2001-6-1'
line4 = 'XXX出生于2001-06-01'
line5 = 'XXX出生于2001-06'

ss = [line1, line2, line3, line4, line5]
regex_str = ".*?出生于(\d{4}[年/-]\d{1,2}([月/-]\d{1,2}|[月/-]$|$))"
for s in ss:
    aa = re.match(regex_str, s)
    if aa:
        print(aa.group(1))

输出：
2001年6月1
2001/6/1
2001-6-1
2001-06-01
2001-06



2 ， 字符串编码

(1)计算机只能处理数字(0跟1)， 文本必须转换成数字才能处理。 计算机中8个bit(表示信息的最小单位，每一位二级制数称为一bit)作为一位字节
(大多数计算机用一个字节表示一个字符、数字或其他字符。), 所以一个字节能表示最大的数字就是255
(2)由于计算机是美国人发明的，所以一个字节就能表示所有的字符了，所以ASCII(一个字节)编码就称为美国人的标准编码，
一个字节来存放一个 ASCII 字符。每一个字节中多余出来的一位（最高位）在计算机内部通常保持为 0 ， 
基本的 ASCII 字符集共有 128 个字符，其中有 96 个可打印字符，包括常用的字母、数字、标点符号等，另外还有 32 个控制字符
(3)但是ASCII处理中文明显是不够的，中文不止255个汉字，所以中国制定了GB2312编码，用两个字节表示一个汉字。
GB2312还把ASCII包含进去了，同理，日文、法文等等上百个国家为了解决这个问题就都发展了一套字节的编码，标准就越来越多，如果出现多个语言混合显示就一定会出现乱码。
(4) 所以unicode编码就出现了，讲所有语言统一到一套编码
(5) 看一下ASCII和unicode编码：
    1）字母A用ASCII编码是十进制是65， 二进制就是0100 0001
    2）汉字‘中’ 已经不在ASCII编码的范围，用unicode编码是20013， 二进制是01001110 00101101
    3）A用unicode编码只需要前面补0，二进制是 00000000 0100 0001

(6) 现在乱码问题解决了，但是如果全是英文，unicode编码比ASCII需要多一倍的存储空间，同时如果传输，也就小多一个传输。
(7) s所以就出现了可变长的编码‘utf-8’ ， 它在遇到英文的时候就变成一个字节，遇到汉字就用三个字节表示。
(8) 一般在内存中编码使用unicode，因为它长度都是一致的，处理起来简单，而utf8则是捉摸不定，所以，内存编码是unicode，而utf8用作传输和文件保存中
这时就需要两者转换了...


3， 编码转换

decode的作用是将其他编码的字符串转换成unicode编码，如str1.decode('gb2312')，表示将gb2312编码的字符串str1转换成unicode编码。
encode的作用是将unicode编码转换成其他编码的字符串，如str2.encode('gb2312')，表示将unicode编码的字符串str2转换成gb2312编码。
